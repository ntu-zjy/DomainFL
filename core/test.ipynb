{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from models.CLIP import Adapter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch.load adapter\n",
    "adapter1 = Adapter(c_in=512, reduction=4, bias=True)\n",
    "adapter1.load_state_dict(torch.load('../weights/0_adapter.pt'))\n",
    "\n",
    "adapter2 = Adapter(c_in=512, reduction=4, bias=True)\n",
    "adapter2.load_state_dict(torch.load('../weights/2_adapter.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('fc.0.weight',\n",
       "              tensor([[ 0.0002,  0.0500, -0.0150,  ..., -0.0270,  0.0182, -0.0579],\n",
       "                      [-0.0116,  0.0345,  0.0159,  ...,  0.0178,  0.0372, -0.0225],\n",
       "                      [ 0.0153, -0.0211,  0.0166,  ...,  0.0184,  0.0561,  0.0131],\n",
       "                      ...,\n",
       "                      [ 0.0116, -0.0066,  0.0131,  ...,  0.0244, -0.0202, -0.0495],\n",
       "                      [ 0.0087, -0.0035, -0.0055,  ..., -0.0357, -0.0120, -0.0481],\n",
       "                      [-0.0139,  0.0197, -0.0367,  ..., -0.0039,  0.0133,  0.0216]])),\n",
       "             ('fc.0.bias',\n",
       "              tensor([-0.0133, -0.0174, -0.0013, -0.0231,  0.0249, -0.0098, -0.0182, -0.0042,\n",
       "                       0.0066, -0.0088,  0.0281,  0.0308,  0.0307,  0.0094, -0.0186,  0.0298,\n",
       "                      -0.0103,  0.0399, -0.0041, -0.0073,  0.0413, -0.0033,  0.0059,  0.0079,\n",
       "                       0.0285, -0.0041,  0.0022,  0.0124,  0.0093,  0.0312,  0.0189,  0.0058,\n",
       "                      -0.0068,  0.0093,  0.0162, -0.0067,  0.0201,  0.0279,  0.0198, -0.0121,\n",
       "                       0.0271,  0.0556,  0.0120, -0.0182,  0.0384, -0.0042,  0.0276, -0.0055,\n",
       "                      -0.0247,  0.0201, -0.0314,  0.0025,  0.0252, -0.0032,  0.0296,  0.0186,\n",
       "                      -0.0281, -0.0074,  0.0183,  0.0233,  0.0116, -0.0053,  0.0406,  0.0106,\n",
       "                       0.0072,  0.0073, -0.0265, -0.0034, -0.0344,  0.0014, -0.0061,  0.0156,\n",
       "                       0.0355,  0.0025,  0.0224,  0.0164, -0.0356,  0.0068,  0.0195,  0.0275,\n",
       "                       0.0398,  0.0164,  0.0104,  0.0225, -0.0004,  0.0046,  0.0040, -0.0039,\n",
       "                       0.0013,  0.0218,  0.0187, -0.0075,  0.0033,  0.0389, -0.0128, -0.0176,\n",
       "                       0.0129,  0.0018,  0.0075, -0.0298,  0.0046, -0.0008, -0.0044, -0.0092,\n",
       "                       0.0506, -0.0152,  0.0107, -0.0180,  0.0241,  0.0174, -0.0043,  0.0190,\n",
       "                       0.0175,  0.0037,  0.0315,  0.0430, -0.0054,  0.0566,  0.0067,  0.0005,\n",
       "                       0.0143, -0.0055,  0.0005,  0.0114, -0.0161,  0.0211, -0.0239,  0.0259])),\n",
       "             ('fc.2.weight',\n",
       "              tensor([[-0.0171, -0.0398,  0.0003,  ...,  0.0384, -0.0072,  0.0135],\n",
       "                      [-0.0081,  0.0563,  0.0117,  ...,  0.0031,  0.0493,  0.0028],\n",
       "                      [ 0.0493, -0.0729,  0.0098,  ...,  0.0173, -0.0072, -0.0088],\n",
       "                      ...,\n",
       "                      [-0.0332,  0.0283, -0.0058,  ..., -0.0219, -0.0352, -0.0237],\n",
       "                      [ 0.0163, -0.0307,  0.0217,  ..., -0.0085,  0.0038, -0.0312],\n",
       "                      [-0.0570, -0.0326,  0.0129,  ...,  0.0832, -0.0355, -0.0334]])),\n",
       "             ('fc.2.bias',\n",
       "              tensor([-0.0083, -0.0286,  0.0153,  0.0238, -0.0025, -0.0244, -0.0022,  0.0052,\n",
       "                      -0.0097,  0.0353, -0.0165,  0.0025,  0.0053, -0.0490,  0.0499,  0.0013,\n",
       "                       0.0168,  0.0146,  0.0234,  0.0217,  0.0002,  0.0543,  0.0172,  0.0341,\n",
       "                       0.0142,  0.0260, -0.0433,  0.0030,  0.0065, -0.0242, -0.0100, -0.0205,\n",
       "                       0.0081, -0.0311, -0.0206,  0.0284,  0.0275,  0.0242,  0.0155,  0.0187,\n",
       "                       0.0124, -0.0030,  0.0225,  0.0096,  0.0102, -0.0104,  0.0076,  0.0080,\n",
       "                      -0.0068, -0.0111,  0.0223,  0.0277,  0.0030,  0.0081,  0.0150,  0.0202,\n",
       "                       0.0031,  0.0115,  0.0252,  0.0072,  0.0072, -0.0232, -0.0297,  0.0285,\n",
       "                      -0.0096, -0.0155, -0.0178,  0.0344,  0.0225, -0.0209,  0.0466, -0.0229,\n",
       "                       0.0416, -0.0222, -0.0389, -0.0081,  0.0002,  0.0119,  0.0226, -0.0157,\n",
       "                       0.0015, -0.0135,  0.0165, -0.0116, -0.0054, -0.0039, -0.0062,  0.0172,\n",
       "                       0.0053,  0.0091, -0.0066, -0.0075,  0.0138,  0.0492, -0.0250,  0.0091,\n",
       "                      -0.0390,  0.0216,  0.0145,  0.0270,  0.0485, -0.0298, -0.0132, -0.0324,\n",
       "                       0.0217,  0.0041,  0.0232, -0.0152,  0.0162,  0.0472,  0.0343,  0.0283,\n",
       "                       0.0191, -0.0084, -0.0173,  0.0086,  0.0395,  0.0436, -0.0196, -0.0045,\n",
       "                       0.0203, -0.0204, -0.0265, -0.0031, -0.0045,  0.0108, -0.0021,  0.0058,\n",
       "                       0.0186,  0.0246, -0.0076, -0.0276,  0.0226, -0.0125,  0.0203,  0.0014,\n",
       "                      -0.0145,  0.0219,  0.0160, -0.0368, -0.0043,  0.0005, -0.0258,  0.0175,\n",
       "                      -0.0085,  0.0103,  0.0194,  0.0206,  0.0357,  0.0289,  0.0172, -0.0131,\n",
       "                       0.0376, -0.0081,  0.0203,  0.0433,  0.0173, -0.0031, -0.0103,  0.0219,\n",
       "                      -0.0151,  0.0077, -0.0067, -0.0142, -0.0189, -0.0029,  0.0195, -0.0300,\n",
       "                       0.0301, -0.0055,  0.0133, -0.0498,  0.0089, -0.0155, -0.0094,  0.0100,\n",
       "                      -0.0055,  0.0094,  0.0208,  0.0099,  0.0069, -0.0211,  0.0131,  0.0270,\n",
       "                       0.0165,  0.0034,  0.0332,  0.0132, -0.0120,  0.0102,  0.0058, -0.0146,\n",
       "                       0.0481, -0.0158, -0.0150,  0.0195, -0.0022,  0.0078,  0.0244,  0.0182,\n",
       "                      -0.0100,  0.0281, -0.0083,  0.0148,  0.0098, -0.0330,  0.0116,  0.0226,\n",
       "                      -0.0385, -0.0506,  0.0096,  0.0219, -0.0282, -0.0379, -0.0331, -0.0084,\n",
       "                      -0.0054,  0.0040, -0.0059,  0.0117, -0.0021,  0.0175,  0.0431,  0.0337,\n",
       "                      -0.0191,  0.0201, -0.0162,  0.0359, -0.0201,  0.0181, -0.0031, -0.0359,\n",
       "                      -0.0400,  0.0156,  0.0265,  0.0090,  0.0226,  0.0476,  0.0015,  0.0171,\n",
       "                       0.0043,  0.0046, -0.0011, -0.0011, -0.0104, -0.0366,  0.0084, -0.0097,\n",
       "                       0.0014,  0.0123,  0.0172,  0.0055,  0.0196, -0.0260,  0.0092, -0.0103,\n",
       "                       0.0036,  0.0078,  0.0269,  0.0150,  0.0134,  0.0305, -0.0206,  0.0120,\n",
       "                       0.0027,  0.0079,  0.0237,  0.0211, -0.0091, -0.0119,  0.0232,  0.0179,\n",
       "                      -0.0018, -0.0077,  0.0422, -0.0495, -0.0052, -0.0252, -0.0445, -0.0107,\n",
       "                       0.0344, -0.0088,  0.0190,  0.0034,  0.0076, -0.0094,  0.0033, -0.0020,\n",
       "                       0.0144,  0.0031,  0.0221, -0.0164, -0.0369,  0.0082, -0.0068,  0.0141,\n",
       "                       0.0124,  0.0014,  0.0331, -0.0165,  0.0611,  0.0210, -0.0105,  0.0270,\n",
       "                       0.0124,  0.0155,  0.0119,  0.0827,  0.0238, -0.0014, -0.0132,  0.0154,\n",
       "                      -0.0138, -0.0230, -0.0264, -0.0032,  0.0284, -0.0044,  0.0271, -0.0140,\n",
       "                       0.0145, -0.0046, -0.0034, -0.0046,  0.0093,  0.0038,  0.0291,  0.0056,\n",
       "                       0.0083,  0.0419, -0.0157,  0.0198,  0.0107, -0.0048,  0.0072,  0.0163,\n",
       "                      -0.0197, -0.0070,  0.0079,  0.0176, -0.0152, -0.0189, -0.0233,  0.0034,\n",
       "                      -0.0054,  0.0463,  0.0087,  0.0100, -0.0367,  0.0254, -0.0045,  0.0600,\n",
       "                       0.0117, -0.0208,  0.0087, -0.0133, -0.0143, -0.0026, -0.0132,  0.0283,\n",
       "                       0.0047, -0.0155,  0.0166, -0.0270, -0.0013, -0.0048,  0.0010, -0.0295,\n",
       "                       0.0221,  0.0212, -0.0028,  0.0043,  0.0056, -0.0023,  0.0205,  0.0238,\n",
       "                       0.0085,  0.0147, -0.0324, -0.0178,  0.0547,  0.0566,  0.0031,  0.0206,\n",
       "                       0.0057,  0.0189,  0.0171, -0.0034,  0.0049, -0.0067,  0.0180,  0.0047,\n",
       "                       0.0025, -0.0114, -0.0053, -0.0040,  0.0247,  0.0122,  0.0143, -0.0169,\n",
       "                      -0.0146, -0.0234,  0.0130,  0.0081,  0.0149,  0.0143, -0.0026, -0.0072,\n",
       "                       0.0040, -0.0188,  0.0033, -0.0074, -0.0245, -0.0243,  0.0055, -0.0089,\n",
       "                       0.0312,  0.0388,  0.0189,  0.0315, -0.0159,  0.0064, -0.0499,  0.0180,\n",
       "                       0.0121, -0.0213,  0.0379,  0.0122,  0.0081,  0.0148,  0.0054, -0.0134,\n",
       "                       0.0145, -0.0227,  0.0256, -0.0223,  0.0151, -0.0065,  0.0023,  0.0109,\n",
       "                      -0.0118,  0.0152, -0.0135,  0.0014,  0.0366, -0.0013,  0.0004,  0.0142,\n",
       "                       0.0494,  0.0042, -0.0180,  0.0071, -0.0009,  0.0174,  0.0231, -0.0077,\n",
       "                      -0.0398,  0.0060,  0.0153, -0.0163,  0.0235,  0.0186,  0.0156, -0.0055,\n",
       "                       0.0287,  0.0312,  0.0071,  0.0186,  0.0273, -0.0101, -0.0021,  0.0269,\n",
       "                      -0.0036, -0.0254, -0.0289, -0.0299,  0.0208,  0.0108, -0.0067, -0.0101,\n",
       "                       0.0203, -0.0441,  0.0179,  0.0082, -0.0129,  0.0117, -0.0369,  0.0066,\n",
       "                       0.0018, -0.0028, -0.0347,  0.0098, -0.0261,  0.0005, -0.0018, -0.0132,\n",
       "                       0.0284, -0.0065,  0.0226,  0.0201,  0.0297,  0.0227,  0.0034, -0.0124,\n",
       "                       0.0249,  0.0282,  0.0116,  0.0266,  0.0131, -0.0087,  0.0184,  0.0046]))])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adapter1.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('fc.0.weight',\n",
       "              tensor([[-0.0389,  0.1063, -0.0929,  ..., -0.0370,  0.0082, -0.0721],\n",
       "                      [ 0.0279,  0.0304, -0.0660,  ...,  0.0687, -0.0152, -0.0128],\n",
       "                      [-0.0015, -0.0368,  0.0412,  ..., -0.0819,  0.0825, -0.0127],\n",
       "                      ...,\n",
       "                      [ 0.0055,  0.0359, -0.0159,  ...,  0.0290, -0.0185,  0.0040],\n",
       "                      [ 0.0556, -0.0552, -0.1014,  ..., -0.1625, -0.0114, -0.0236],\n",
       "                      [ 0.0427,  0.0605, -0.0414,  ..., -0.0442, -0.0170, -0.0180]])),\n",
       "             ('fc.0.bias',\n",
       "              tensor([ 0.0036, -0.0354, -0.0101, -0.0096, -0.0028, -0.0245, -0.0252, -0.0019,\n",
       "                       0.0123,  0.0079,  0.0162,  0.0159,  0.0242,  0.0068, -0.0288,  0.0245,\n",
       "                      -0.0214,  0.0327, -0.0221, -0.0073,  0.0158, -0.0017, -0.0024, -0.0001,\n",
       "                       0.0283, -0.0084,  0.0022,  0.0155,  0.0038,  0.0114, -0.0023, -0.0138,\n",
       "                      -0.0151,  0.0216,  0.0286, -0.0172,  0.0075,  0.0114,  0.0185, -0.0374,\n",
       "                       0.0306,  0.0276,  0.0171, -0.0249,  0.0438, -0.0031,  0.0289, -0.0221,\n",
       "                      -0.0138,  0.0198, -0.0338, -0.0056,  0.0151,  0.0039,  0.0116,  0.0064,\n",
       "                      -0.0257, -0.0326,  0.0397,  0.0081,  0.0042, -0.0282,  0.0426,  0.0025,\n",
       "                       0.0076,  0.0038, -0.0343, -0.0039, -0.0395, -0.0048, -0.0182,  0.0129,\n",
       "                       0.0149, -0.0064, -0.0166, -0.0009, -0.0170, -0.0127,  0.0259,  0.0241,\n",
       "                       0.0432, -0.0014,  0.0092,  0.0037, -0.0035,  0.0091, -0.0010, -0.0093,\n",
       "                      -0.0073,  0.0231,  0.0129, -0.0249, -0.0070,  0.0080, -0.0178, -0.0158,\n",
       "                       0.0117, -0.0096, -0.0039, -0.0396,  0.0071, -0.0287, -0.0162, -0.0008,\n",
       "                       0.0395, -0.0277,  0.0050, -0.0381,  0.0161,  0.0109, -0.0314,  0.0068,\n",
       "                      -0.0072, -0.0018,  0.0172,  0.0269, -0.0274,  0.0409, -0.0023, -0.0110,\n",
       "                      -0.0026, -0.0190, -0.0028,  0.0020, -0.0272,  0.0133, -0.0509,  0.0227])),\n",
       "             ('fc.2.weight',\n",
       "              tensor([[-0.0229, -0.0184,  0.0753,  ...,  0.1137,  0.0654,  0.0294],\n",
       "                      [-0.0609,  0.0132, -0.0005,  ...,  0.0028,  0.0789,  0.0018],\n",
       "                      [ 0.0825, -0.0511, -0.0246,  ...,  0.0274, -0.0304,  0.0201],\n",
       "                      ...,\n",
       "                      [-0.1143, -0.0162,  0.0749,  ...,  0.0057, -0.0218,  0.0154],\n",
       "                      [ 0.0174, -0.0324,  0.0002,  ..., -0.0121, -0.0056, -0.0318],\n",
       "                      [ 0.0076,  0.0253, -0.0219,  ...,  0.0376, -0.0385, -0.0518]])),\n",
       "             ('fc.2.bias',\n",
       "              tensor([ 1.4439e-02, -1.0260e-02,  2.8676e-02,  1.9471e-02,  3.5206e-03,\n",
       "                      -2.5175e-02, -1.3912e-02,  5.3520e-03, -5.8026e-03,  6.2370e-02,\n",
       "                      -2.5666e-02,  2.0323e-02,  5.6624e-03, -4.5982e-02,  5.3260e-02,\n",
       "                       4.2006e-03,  1.9172e-02,  1.6174e-02,  2.3663e-02,  3.9711e-02,\n",
       "                       8.5028e-03,  5.0169e-02,  1.2911e-02,  2.4566e-02,  1.5175e-02,\n",
       "                       3.4906e-02, -1.6087e-02,  1.0315e-02,  1.9625e-02, -3.1600e-02,\n",
       "                      -7.4146e-04, -2.4997e-02,  2.3578e-02, -2.0727e-02, -1.4080e-02,\n",
       "                       4.3237e-03,  5.4848e-02,  2.6762e-02,  2.2718e-02,  1.7979e-02,\n",
       "                       1.8073e-02,  1.7150e-02,  2.4110e-02,  6.5477e-03,  2.2173e-02,\n",
       "                      -1.2359e-02,  1.1908e-02, -1.2854e-02, -1.5332e-02, -1.9231e-02,\n",
       "                       1.6796e-02,  2.9635e-02, -1.7878e-02,  2.3274e-02,  7.1701e-03,\n",
       "                       2.3999e-02,  1.1961e-02,  1.0184e-02,  2.4046e-02, -1.2406e-02,\n",
       "                       8.6748e-03, -5.0037e-03, -1.8456e-02,  3.8584e-02,  1.0360e-03,\n",
       "                      -9.5942e-03, -1.4143e-02,  5.4311e-03, -3.9205e-03, -9.8675e-03,\n",
       "                       5.2406e-02, -2.7555e-02,  2.9444e-02, -2.0240e-02, -6.6642e-02,\n",
       "                      -2.3649e-02,  1.0072e-02,  4.2897e-03,  2.7427e-02, -9.5454e-03,\n",
       "                      -1.6307e-02, -8.1438e-03,  2.4153e-02, -1.2329e-03, -2.2355e-02,\n",
       "                       1.2884e-02,  1.0851e-02,  1.9036e-02,  9.6575e-03,  8.2042e-03,\n",
       "                      -3.5582e-04, -1.7826e-03,  1.2390e-02,  2.1339e-02, -4.8392e-02,\n",
       "                       4.9201e-04, -2.9204e-02,  1.9341e-02, -9.5127e-04,  3.2487e-02,\n",
       "                       4.5311e-02, -1.8193e-02, -6.2971e-03, -2.4130e-02,  2.0498e-02,\n",
       "                       3.9892e-03,  7.7337e-03, -1.8937e-02,  1.6325e-02,  2.1366e-02,\n",
       "                       3.3510e-02,  1.3769e-02,  1.5967e-02, -8.0198e-03, -6.0697e-03,\n",
       "                       8.3947e-03,  4.2737e-02,  4.1132e-02, -3.1358e-02, -3.3839e-03,\n",
       "                       1.4832e-02, -3.0398e-02, -1.3130e-02,  1.4300e-03, -3.0435e-02,\n",
       "                       1.6459e-02,  2.5858e-04, -1.2454e-02,  1.4183e-02,  2.1427e-02,\n",
       "                      -7.5642e-03, -6.8125e-03,  2.4276e-02, -7.3502e-03,  1.0436e-02,\n",
       "                       7.2121e-03, -7.8662e-03,  2.3570e-02,  3.6181e-02, -1.2424e-02,\n",
       "                       1.3329e-02, -3.1784e-03, -1.4381e-02,  1.8863e-02, -1.3874e-02,\n",
       "                       5.2081e-03,  1.7057e-02,  2.2715e-02,  1.1063e-02,  3.3011e-02,\n",
       "                       2.2865e-02, -8.5373e-04,  2.1651e-02, -8.8228e-03,  2.2201e-02,\n",
       "                       3.8082e-02,  4.6638e-03,  1.1700e-02, -2.6628e-02,  4.8972e-02,\n",
       "                      -1.5870e-02,  1.6610e-02,  5.1006e-03, -6.5574e-03, -1.2359e-02,\n",
       "                       9.2306e-04,  2.3666e-02, -3.6290e-02,  4.1139e-02, -1.4404e-02,\n",
       "                       7.2010e-03, -2.9198e-02,  1.0461e-02, -6.9408e-03, -1.8570e-02,\n",
       "                       1.9427e-02, -6.6072e-03,  1.1659e-02, -4.8803e-02,  9.2505e-03,\n",
       "                       5.4260e-03, -3.1418e-02,  1.4068e-02,  3.9975e-02,  8.8086e-03,\n",
       "                       5.6075e-03,  3.8535e-02,  2.4243e-02, -1.7198e-02,  1.1513e-02,\n",
       "                       8.7459e-03, -2.9665e-03,  5.1776e-02, -2.3026e-02, -1.1999e-02,\n",
       "                       3.5455e-05,  2.0681e-03, -1.2298e-02,  2.8710e-02,  2.2771e-02,\n",
       "                      -8.0532e-03,  2.6011e-02, -2.7229e-02,  1.3903e-02, -1.0182e-02,\n",
       "                      -2.9506e-02,  1.4813e-02,  2.9260e-02, -5.3760e-02, -5.2220e-02,\n",
       "                       2.2081e-02,  2.6176e-02, -1.2164e-02, -4.8027e-02, -3.2373e-02,\n",
       "                      -2.5750e-03,  2.3553e-04,  5.7739e-03, -2.0783e-02,  2.2449e-02,\n",
       "                      -1.0886e-02, -6.6975e-03,  3.8948e-02,  9.1291e-03, -2.2034e-02,\n",
       "                       1.8577e-02, -2.0677e-02,  4.3321e-02, -2.8355e-03,  1.6202e-02,\n",
       "                       8.7408e-03, -1.9294e-02, -4.4108e-02,  9.8652e-03,  2.7627e-02,\n",
       "                       5.8082e-03,  1.5757e-02,  2.0518e-02, -1.4545e-02,  2.7102e-02,\n",
       "                       2.4965e-02,  3.9163e-03, -3.9654e-04, -9.1740e-03, -1.3982e-02,\n",
       "                      -4.5661e-02,  3.3421e-03,  5.0100e-03, -3.2973e-03,  7.0423e-03,\n",
       "                       1.4941e-02,  1.4250e-02,  6.4152e-03, -1.2703e-02,  5.7534e-03,\n",
       "                       1.7973e-02,  9.4302e-03, -6.5858e-03,  2.3955e-02,  7.7889e-03,\n",
       "                       2.0629e-02,  2.4789e-02, -1.0320e-02,  2.4697e-02,  5.9361e-03,\n",
       "                       1.3277e-02,  1.7132e-02,  2.4736e-02, -6.0024e-03, -6.7320e-03,\n",
       "                       9.0308e-03,  2.1606e-02, -1.6132e-02, -4.7645e-03,  4.4780e-02,\n",
       "                      -4.3518e-02, -1.4187e-02, -2.5164e-02, -4.4117e-02,  9.8038e-03,\n",
       "                       3.4843e-02, -6.8109e-03,  1.9469e-02,  5.1925e-04,  3.1548e-03,\n",
       "                      -2.6189e-02, -1.1551e-02, -4.5698e-03,  2.8700e-02, -3.1174e-02,\n",
       "                       1.6555e-02, -1.2807e-02, -2.2122e-02,  1.8477e-02, -7.1329e-03,\n",
       "                       1.0169e-02,  1.7869e-02, -7.6052e-04,  4.3190e-02,  1.3873e-02,\n",
       "                       1.9195e-02,  3.5019e-02, -1.2231e-02,  2.4784e-02, -4.2698e-03,\n",
       "                       2.6034e-02,  2.0885e-02,  1.4821e-01,  2.1505e-02, -1.0731e-02,\n",
       "                      -2.8013e-03,  2.3360e-02, -1.6190e-02,  5.6197e-03, -4.3496e-02,\n",
       "                       2.6616e-03,  2.7280e-02, -5.5200e-03,  2.6548e-02,  1.4115e-03,\n",
       "                       2.0784e-03,  8.0015e-03,  4.7060e-03, -8.8508e-03,  1.1541e-02,\n",
       "                       1.1482e-02, -5.7037e-03,  7.2263e-03,  1.5657e-02,  4.2720e-02,\n",
       "                      -1.3124e-02,  1.3265e-02,  7.5465e-03,  6.2423e-03,  1.3177e-02,\n",
       "                       1.1632e-02, -3.5735e-02, -4.1103e-03,  1.2593e-02,  7.1275e-03,\n",
       "                      -4.9928e-03, -1.6333e-02, -4.0155e-02, -1.2667e-02, -1.3741e-03,\n",
       "                       4.0464e-02,  7.7230e-03, -1.5948e-02, -2.2854e-02,  3.2591e-02,\n",
       "                      -1.0769e-03,  5.3097e-02,  2.0202e-02, -1.4131e-02, -9.8124e-03,\n",
       "                      -5.8418e-03, -2.7183e-02, -5.9254e-03, -9.4312e-03,  1.5815e-02,\n",
       "                       1.0601e-02,  4.2430e-03,  1.2225e-02, -1.3597e-02, -2.2289e-03,\n",
       "                      -1.7716e-02,  7.2386e-03, -2.4879e-02,  2.0454e-02,  2.2364e-02,\n",
       "                       4.3749e-03, -7.6986e-03,  3.7213e-03,  1.3258e-02,  2.0843e-02,\n",
       "                       7.3583e-03,  4.8854e-03,  2.1205e-02, -3.3297e-02, -1.8534e-02,\n",
       "                       3.6504e-02,  3.1264e-02,  3.8472e-03,  2.2975e-02,  7.2955e-03,\n",
       "                       1.1560e-02,  2.2627e-02, -1.5747e-02,  8.8825e-03,  1.7119e-02,\n",
       "                       1.1487e-02, -6.9554e-03,  2.4058e-02, -3.6731e-03, -2.2887e-02,\n",
       "                      -2.4258e-03,  3.7660e-02,  2.8436e-02,  3.1012e-02, -8.5040e-03,\n",
       "                      -2.6037e-02, -8.2300e-03,  5.4975e-03,  9.5648e-03,  1.4568e-02,\n",
       "                       1.5307e-02, -5.3219e-03,  1.8917e-02,  5.2340e-03, -3.3301e-02,\n",
       "                       9.8884e-03, -9.2957e-03, -2.1428e-02, -1.7726e-02,  2.8617e-03,\n",
       "                       1.0139e-02,  3.1835e-02,  4.9338e-02,  1.0924e-02,  3.8015e-02,\n",
       "                      -6.5097e-03, -4.4330e-04, -4.4376e-02,  1.9435e-03,  2.9334e-02,\n",
       "                      -1.8697e-02,  2.2342e-02,  1.4508e-02,  2.7666e-02, -6.8589e-03,\n",
       "                       5.4703e-03, -2.4067e-02,  2.5368e-02, -2.4661e-02,  4.2914e-02,\n",
       "                      -2.0985e-02,  2.4432e-02, -1.3673e-02, -3.5170e-04,  1.3134e-02,\n",
       "                      -1.2897e-02,  3.2886e-02, -8.1690e-04,  1.0556e-02,  5.0276e-02,\n",
       "                      -5.6672e-03,  1.3510e-03,  1.2309e-02,  6.6403e-02, -2.8888e-02,\n",
       "                      -9.0015e-03, -6.8593e-04,  5.1047e-03,  1.8456e-02,  1.8765e-02,\n",
       "                      -1.0653e-02, -4.2955e-02, -2.2685e-03, -2.0758e-03,  4.2499e-03,\n",
       "                       2.3820e-03,  2.0917e-02,  3.0608e-02, -1.2953e-02,  3.3782e-02,\n",
       "                       4.0551e-02,  1.0285e-02,  2.9021e-02,  1.8412e-02, -4.7317e-03,\n",
       "                      -1.7059e-02,  3.6775e-02, -1.1188e-02, -4.9558e-02, -1.6474e-02,\n",
       "                      -2.0959e-02,  2.6433e-02,  9.1032e-03,  4.3640e-03, -2.9945e-02,\n",
       "                       1.4289e-02, -1.7491e-02,  2.7638e-02,  8.4642e-03, -1.6721e-02,\n",
       "                       1.0769e-02, -3.0694e-02, -1.3202e-02,  9.2893e-03,  2.9716e-04,\n",
       "                      -1.9382e-02,  1.4387e-02, -1.9098e-02,  9.7581e-03, -3.8076e-03,\n",
       "                      -3.2183e-02,  3.8608e-02,  1.9681e-02,  1.1000e-02,  9.1971e-03,\n",
       "                       3.7410e-02,  3.4051e-02, -1.7477e-03, -1.4143e-02,  2.6107e-02,\n",
       "                       2.9775e-02,  1.2490e-02,  3.5127e-02,  2.3940e-02,  1.1685e-02,\n",
       "                       2.6284e-03, -1.3216e-03]))])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adapter2.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fc.0.weight vs fc.0.weight: diff=13.572736740112305, cos=0.2932654023170471\n",
      "fc.0.bias vs fc.0.bias: diff=0.1520899534225464, cos=0.7863556742668152\n",
      "fc.2.weight vs fc.2.weight: diff=10.942910194396973, cos=0.43735986948013306\n",
      "fc.2.bias vs fc.2.bias: diff=0.2769106924533844, cos=0.8472673892974854\n"
     ]
    }
   ],
   "source": [
    "for (name1, param1), (name2, param2) in zip(adapter1.named_parameters(), adapter2.named_parameters()):\n",
    "    # norm diff\n",
    "    diff = torch.norm(param1 - param2).item()\n",
    "\n",
    "    # cal cosine similarity\n",
    "    cos = torch.nn.functional.cosine_similarity(param1.flatten(), param2.flatten(), dim=0)\n",
    "\n",
    "    print(f'{name1} vs {name2}: diff={diff}, cos={cos}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import copy\n",
    "x1 = torch.arange(6).view(2,-1).type(torch.float64)\n",
    "g1 = nn.Linear(3,2, bias=False).type(torch.float64)\n",
    "g2 = nn.Linear(2,3, bias=False).type(torch.float64)\n",
    "l1 = nn.Linear(3,2, bias=False).type(torch.float64)\n",
    "l2 = nn.Linear(2,3, bias=False).type(torch.float64)\n",
    "\n",
    "w1 = torch.randn(2,2).type(torch.float64)\n",
    "w2 = torch.randn(3,3).type(torch.float64)\n",
    "\n",
    "G1 = g1(x1) @ w1\n",
    "L1 = l1(x1) @ w1\n",
    "G1 = G1 + L1\n",
    "G2 = g2(G1) @ w2\n",
    "L2 = l2(G1) @ w2\n",
    "\n",
    "g1_ = copy.deepcopy(g1)\n",
    "g2_ = copy.deepcopy(g2)\n",
    "l1_ = copy.deepcopy(l1)\n",
    "l2_ = copy.deepcopy(l2)\n",
    "\n",
    "g1_.weight.data = w1.t() @ g1.weight.data.clone()\n",
    "g2_.weight.data = w2.t() @ g2.weight.data.clone()\n",
    "l1_.weight.data = w1.t() @ l1.weight.data.clone()\n",
    "l2_.weight.data = w2.t() @ l2.weight.data.clone()\n",
    "\n",
    "G1_ = g1_(x1)\n",
    "L1_ = l1_(x1)\n",
    "G1_ = G1_ + L1_\n",
    "G2_ = g2_(G1)\n",
    "L2_ = l2_(G1)\n",
    "\n",
    "print(torch.equal(G1, G1_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.equal(g1(x1) @ w1 , x1 @ g1.weight.data.t() @ w1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.4110,  0.6556],\n",
       "        [-1.0680,  1.7786]], dtype=torch.float64, grad_fn=<MmBackward0>)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g1(x1) @ w1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.4110,  0.6556],\n",
       "        [-1.0680,  1.7786]], dtype=torch.float64)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1 @ g1.weight.data.t() @ w1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.4110,  0.6556],\n",
       "        [-1.0680,  1.7786]], dtype=torch.float64)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1 @ (w1.T @ g1.weight.data).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0.],\n",
       "        [0., 0.]], dtype=torch.float64)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1 @ (g1.weight.data.t() @ w1) - x1 @ (w1.T @ g1.weight.data).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.equal(g1(x1) , x1 @ g1.weight.data.t())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.equal(g1(x1) @ w1 , x1 @ (g1.weight.data.t() @ w1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.equal(x1 @ g1.weight.data.t() @ w1 , x1 @ (g1.weight.data.t() @ w1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.equal(x1 @ (w1.T @ g1.weight.data).T , x1 @ (g1.weight.data.T @ w1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.equal(g1(x1) @ w1, x1 @ (w1.T @ g1.weight.data).T)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
