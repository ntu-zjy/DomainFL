{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Need experimental calculation:\n",
    "$$\\triangle_2 f_i = \\left(\\text{max}_{p,q} \\frac{\\left \\| d_p^{(i)} - d_q^{(i)} \\right \\|_2}{n_i}\\right)$$\n",
    "$d$ is data embedding, $n_i$ is the number of data points in the $i$-th class, $p$ and $q$ are data points in the $i$-th class\n",
    "\n",
    "for $(\\delta_i, \\varepsilon_i)-dp$ guanrantee:\n",
    "\n",
    "$$\\sigma_i \\ge \\frac{\\sqrt{2ln(1.25/\\delta_i)} \\cdot \\triangle_2 f_i }{\\varepsilon_i}$$\n",
    "\n",
    "usually take $\\varepsilon=1$ for $\\delta$, make sense if $\\delta < \\frac{1}{n_i}$. acceptable for $\\varepsilon < 10$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/DomainFL/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/opt/conda/envs/DomainFL/lib/python3.11/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers\n",
      "  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.layers\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "build data Clipart classification head\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 150/150 [00:01<00:00, 106.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "build data Painting classification head\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 150/150 [00:01<00:00, 120.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "build data Real classification head\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 150/150 [00:01<00:00, 118.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "build data Sketch classification head\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 150/150 [00:01<00:00, 118.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "build data Quickdraw classification head\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 150/150 [00:01<00:00, 116.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "build data Infograph classification head\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 150/150 [00:01<00:00, 109.28it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([60.73185884, 12.14637177,  6.07318588,  1.21463718])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subset_size = 150\n",
    "\n",
    "import copy\n",
    "import torch\n",
    "import argparse\n",
    "from models.CLIP import *\n",
    "from utils.get_data import domainnet\n",
    "from utils.get_data import get_data\n",
    "from utils.data_utils import build_subset, split_train_and_val\n",
    "from utils.server import Server\n",
    "from utils.clientours import Client\n",
    "import warnings\n",
    "import numpy as np\n",
    "warnings.simplefilter(\"ignore\")\n",
    "\n",
    "torch.manual_seed(1)\n",
    "torch.cuda.manual_seed(1) if torch.cuda.is_available() else None\n",
    "\n",
    "parser = argparse.ArgumentParser(description='DomainFL')\n",
    "parser.add_argument('-d','--dataset', type=str, default='domainnet', help='Dataset name')\n",
    "parser.add_argument('-ss','--subset_size', type=int, default=subset_size, help='Subset size')\n",
    "parser.add_argument('-m','--model', type=str, default='CLIP', help='Model name')\n",
    "parser.add_argument('-ien','--image_encoder_name', type=str, default='ViT-B-32', help='Image encoder name')\n",
    "parser.add_argument('-optim','--optimizer', type=str, default='AdamW', help='Optimizer name')\n",
    "parser.add_argument('-lr','--lr', type=float, default=1e-3, help='Learning rate')\n",
    "parser.add_argument('-clip','--clip', type=float, default=1, help='Gradient clip')\n",
    "parser.add_argument('-bs','--batch_size', type=int, default=32, help='Batch size')\n",
    "parser.add_argument('-le','--local_epochs', type=int, default=1, help='Number of epochs')\n",
    "parser.add_argument('-warm_up','--warm_up', type=int, default=10, help='Warm up epochs')\n",
    "parser.add_argument('-gr','--global_rounds', type=int, default=200, help='Number of global rounds')\n",
    "parser.add_argument('-device','--device', type=str, default='cuda', help='Device')\n",
    "parser.add_argument('-num_workers','--num_workers', type=int, default=12, help='Number of workers')\n",
    "parser.add_argument('-eval','--eval_interval', type=int, default=200, help='Log interval')\n",
    "parser.add_argument('-did','--device_id', type=str, default=0, help='Device ID')\n",
    "parser.add_argument('-seed','--seed', type=int, default=1, help='Seed')\n",
    "parser.add_argument('-rw','--regularization_weight', type=float, default=0, help='Regularization weight')\n",
    "parser.add_argument('-kdw','--kd_loss_weight', type=float, default=0, help='KD loss weight')\n",
    "parser.add_argument('-sra','--sample_ratio', type=float, default=0.1, help='Sample ratio of all embeddings')\n",
    "parser.add_argument('-sram','--sample_ratio_method', type=str, default='cluster', help='Sample ratio method (random or cluster, mixed)')\n",
    "parser.add_argument('-dp','--diff_privacy', type=float, default=0, help='Diff privacy scale')\n",
    "\n",
    "args, unknown = parser.parse_known_args()\n",
    "\n",
    "# initialize server\n",
    "server = Server(args)\n",
    "\n",
    "# set dataset\n",
    "dataset = globals()[args.dataset]\n",
    "\n",
    "# initialize clients\n",
    "# client image encoder is the same as the global image encoder\n",
    "clients = []\n",
    "cls_heads = []\n",
    "for id, data_name in enumerate(dataset):\n",
    "    init_image_encoder = copy.deepcopy(server.image_encoder)\n",
    "    cd = get_data(data_name, server.train_preprocess, server.val_preprocess, args.batch_size, args.num_workers)\n",
    "    cd = build_subset(cd, args.subset_size)\n",
    "    cd = split_train_and_val(cd)\n",
    "    cls_head = server.generate_cls_head(cd, data_name)\n",
    "    client = Client(args, id, cd.train_dataset, cd.test_dataset, cd.val_dataset, cd.train_loader, cd.test_loader, cd.val_loader, cd.classnames, init_image_encoder, cls_head, data_name)\n",
    "    clients.append(client)\n",
    "    cls_heads.append(cls_head)\n",
    "    del cd\n",
    "\n",
    "def cal_privacy_preservation_epsilon(distances, ns, sigma=0.05):\n",
    "    return [distances[i] * np.sqrt(2*np.log(1.25/(1/ns[i]))) / sigma for i in range(len(distances))]\n",
    "\n",
    "from collections import defaultdict\n",
    "clients_eps = []\n",
    "for client in clients:\n",
    "    train_dataloader = client.train_dataloader\n",
    "    device = client.device\n",
    "    protos = defaultdict(list)\n",
    "    model = client.model\n",
    "    model.train()\n",
    "\n",
    "    for i, (inputs, labels) in enumerate(train_dataloader):\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        rep = model.base.model.encode_image(inputs)\n",
    "\n",
    "        for i, yy in enumerate(labels):\n",
    "            y_c = yy.item()\n",
    "            protos[y_c].append(rep[i, :].detach().data)\n",
    "\n",
    "    max_distance_each_client = 0\n",
    "    max_n = 0\n",
    "    distances = []\n",
    "    ns = []\n",
    "    for i in protos.keys():\n",
    "        # 求两两torch之差的二范数的最大值\n",
    "        tensor_list = protos[i]\n",
    "        max_distance_each_class = 0  # 初始化最大距离\n",
    "        max_n_each_class = 0\n",
    "        # 双重循环遍历每一对不同的 tensor 组合\n",
    "        for j in range(len(tensor_list)):\n",
    "            for k in range(j + 1, len(tensor_list)):\n",
    "                # 计算两个 tensor 之间的差的二范数\n",
    "                distance = torch.norm(tensor_list[j] - tensor_list[k], p=2)\n",
    "                distance = distance.item() / len(tensor_list)\n",
    "\n",
    "                # 更新最大距离\n",
    "                if distance > max_distance_each_class:\n",
    "                    max_distance_each_class = distance\n",
    "                    max_n_each_class = len(tensor_list)\n",
    "\n",
    "        distances.append(max_distance_each_class)\n",
    "        ns.append(max_n_each_class)\n",
    "\n",
    "    n_mean = sum(ns) / len(ns)\n",
    "    clients_eps.append([np.mean(cal_privacy_preservation_epsilon(distances, ns, sigma=s)) for s in [0.01, 0.05, 0.1, 0.5]])\n",
    "\n",
    "clients_eps = np.array(clients_eps)\n",
    "clients_eps.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_privacy_preservation_epsilon(distances, ns, sigma=0.05):\n",
    "    return [distances[i] * np.sqrt(2*np.log(1.25/(1/ns[i]))) / sigma for i in range(len(distances))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[78.7242065480313, 15.744841309606262, 7.872420654803131, 1.574484130960626],\n",
       " [63.55926843492639, 12.711853686985277, 6.355926843492639, 1.271185368698528],\n",
       " [29.472535266615754,\n",
       "  5.894507053323151,\n",
       "  2.9472535266615756,\n",
       "  0.5894507053323151],\n",
       " [47.16584317607657, 9.433168635215313, 4.716584317607657, 0.9433168635215314],\n",
       " [14.365247953654048,\n",
       "  2.8730495907308096,\n",
       "  1.4365247953654048,\n",
       "  0.28730495907308096],\n",
       " [95.28364072673891,\n",
       "  19.056728145347783,\n",
       "  9.528364072673892,\n",
       "  1.9056728145347788]]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import defaultdict\n",
    "clients_eps = []\n",
    "for client in clients:\n",
    "    train_dataloader = client.train_dataloader\n",
    "    device = client.device\n",
    "    protos = defaultdict(list)\n",
    "    model = client.model\n",
    "    model.train()\n",
    "\n",
    "    for i, (inputs, labels) in enumerate(train_dataloader):\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        rep = model.base.model.encode_image(inputs)\n",
    "\n",
    "        for i, yy in enumerate(labels):\n",
    "            y_c = yy.item()\n",
    "            protos[y_c].append(rep[i, :].detach().data)\n",
    "\n",
    "    max_distance_each_client = 0\n",
    "    max_n = 0\n",
    "    distances = []\n",
    "    ns = []\n",
    "    for i in protos.keys():\n",
    "        # 求两两torch之差的二范数的最大值\n",
    "        tensor_list = protos[i]\n",
    "        max_distance_each_class = 0  # 初始化最大距离\n",
    "        max_n_each_class = 0\n",
    "        # 双重循环遍历每一对不同的 tensor 组合\n",
    "        for j in range(len(tensor_list)):\n",
    "            for k in range(j + 1, len(tensor_list)):\n",
    "                # 计算两个 tensor 之间的差的二范数\n",
    "                distance = torch.norm(tensor_list[j] - tensor_list[k], p=2)\n",
    "                distance = distance.item() / len(tensor_list)\n",
    "\n",
    "                # 更新最大距离\n",
    "                if distance > max_distance_each_class:\n",
    "                    max_distance_each_class = distance\n",
    "                    max_n_each_class = len(tensor_list)\n",
    "\n",
    "        distances.append(max_distance_each_class)\n",
    "        ns.append(max_n_each_class)\n",
    "\n",
    "    n_mean = sum(ns) / len(ns)\n",
    "    clients_eps.append([np.mean(cal_privacy_preservation_epsilon(distances, ns, sigma=s)) for s in [0.01, 0.05, 0.1, 0.5]])\n",
    "\n",
    "clients_eps = np.array(clients_eps)\n",
    "clients_eps.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([54.76179035, 10.95235807,  5.47617904,  1.09523581])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clients_eps = np.array(clients_eps)\n",
    "clients_eps.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "78.7713252813224"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(cal_privacy_preservation_epsilon(distances, ns, sigma=0.01))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15.75426505626448"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(cal_privacy_preservation_epsilon(distances, ns, sigma=0.05))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.87713252813224"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(cal_privacy_preservation_epsilon(distances, ns, sigma=0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.575426505626448"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(cal_privacy_preservation_epsilon(distances, ns, sigma=0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max distance for each client: 0.9616207758585612\n",
      "Max n: 15\n",
      "Max distance for each client: 1.5717161723545618\n",
      "Max n: 7\n",
      "Max distance for each client: 0.843130953171674\n",
      "Max n: 17\n",
      "Max distance for each client: 0.49717400624201846\n",
      "Max n: 26\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 17\u001b[0m\n\u001b[1;32m     14\u001b[0m         y_c \u001b[38;5;241m=\u001b[39m yy\u001b[38;5;241m.\u001b[39mitem()\n\u001b[1;32m     15\u001b[0m         protos[y_c]\u001b[38;5;241m.\u001b[39mappend(rep[i, :]\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mdata)\n\u001b[0;32m---> 17\u001b[0m max_distance_each_client, max_n_each_client \u001b[38;5;241m=\u001b[39m \u001b[43mlow_bound_privacy_preservation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprotos\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m max_distance_each_client \u001b[38;5;241m>\u001b[39m max_distance:\n\u001b[1;32m     19\u001b[0m     max_distance \u001b[38;5;241m=\u001b[39m max_distance_each_client\n",
      "Cell \u001b[0;32mIn[18]\u001b[0m, in \u001b[0;36mlow_bound_privacy_preservation\u001b[0;34m(protos)\u001b[0m\n\u001b[1;32m      0\u001b[0m <Error retrieving source code with stack_data see ipython/ipython#13598>\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "max_distance, max_n = 0, 0\n",
    "for client in clients:\n",
    "    train_dataloader = client.train_dataloader\n",
    "    device = client.device\n",
    "    protos = defaultdict(list)\n",
    "    model = client.model\n",
    "    model.train()\n",
    "\n",
    "    for i, (inputs, labels) in enumerate(train_dataloader):\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        rep = model.base.model.encode_image(inputs)\n",
    "\n",
    "        for i, yy in enumerate(labels):\n",
    "            y_c = yy.item()\n",
    "            protos[y_c].append(rep[i, :].detach().data)\n",
    "\n",
    "    max_distance_each_client, max_n_each_client = low_bound_privacy_preservation(protos)\n",
    "    if max_distance_each_client > max_distance:\n",
    "        max_distance = max_distance_each_client\n",
    "        max_n = max_n_each_client\n",
    "\n",
    "print(\"privacy preservation lower bound:\", max_distance * np.sqrt(2*np.log(1.25/(1/max_n))) / 0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_distance, mean_n = 0, 0\n",
    "mean_distance_list, mean_n_list = [], []\n",
    "for client in clients:\n",
    "    train_dataloader = client.train_dataloader\n",
    "    device = client.device\n",
    "    protos = defaultdict(list)\n",
    "    model = client.model\n",
    "    model.train()\n",
    "\n",
    "    for i, (inputs, labels) in enumerate(train_dataloader):\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        rep = model.base.model.encode_image(inputs)\n",
    "\n",
    "        for i, yy in enumerate(labels):\n",
    "            y_c = yy.item()\n",
    "            protos[y_c].append(rep[i, :].detach().data)\n",
    "\n",
    "    mean_distance_each_client, mean_n_each_client = mean_privacy_preservation(protos)\n",
    "    mean_distance_list.append(mean_distance_each_client)\n",
    "    mean_n_list.append(mean_n_each_client)\n",
    "\n",
    "mean_distance = sum(mean_distance_list) / len(mean_distance_list)\n",
    "mean_n = sum(mean_n_list) / len(mean_n_list)\n",
    "\n",
    "print(\"privacy preservation mean:\", mean_distance * np.sqrt(2*np.log(1.25/(1/mean_n))) / 0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.547179796051914"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_distance * np.sqrt(2*np.log(1.25/(1/max_n))) / 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.5717161723545618"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.169053700369523"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.log(1.25/(1/max_n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_distance, mean_n = mean_privacy_preservation(protos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.025850887242276535"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "280.0"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.7696714831449774"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_distance * np.sqrt(2*np.log(1.25/(1/mean_n))) / 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "for client in [clients[0]]:\n",
    "    train_dataloader = client.train_dataloader\n",
    "    device = client.device\n",
    "    protos = defaultdict(list)\n",
    "    model = client.model\n",
    "    model.train()\n",
    "\n",
    "    for i, (inputs, labels) in enumerate(train_dataloader):\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        rep = model.base.model.encode_image(inputs)\n",
    "\n",
    "        for i, yy in enumerate(labels):\n",
    "            y_c = yy.item()\n",
    "            protos[y_c].append(rep[i, :].detach().data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max distance for each client: 0.9624424616495768\n",
      "Max n: 15\n"
     ]
    }
   ],
   "source": [
    "max_distance_each_client, max_n_each_client = low_bound_privacy_preservation(protos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23.30301078831292"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_distance_each_client * np.sqrt(2*np.log(1.25/(1/max_n))) / 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.150179973565593"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_distance_each_client * np.sqrt(2*np.log(1.25/(1/mean_n))) / 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_distance_each_client = 0\n",
    "mean_n = 0\n",
    "n_list = []\n",
    "distance_each_client_list = []\n",
    "for i in protos.keys():\n",
    "    # 求两两torch之差的二范数的平均值\n",
    "    tensor_list = protos[i]\n",
    "    n_list.append(len(tensor_list))\n",
    "    mean_distance_each_class = 0  # 初始化距离之和\n",
    "    distance_each_class_list = []  # 初始化距离列表\n",
    "    # 双重循环遍历每一对不同的 tensor 组合\n",
    "    for j in range(len(tensor_list)):\n",
    "        for k in range(j + 1, len(tensor_list)):\n",
    "            # 计算两个 tensor 之间的差的二范数\n",
    "            distance = torch.norm(tensor_list[j] - tensor_list[k], p=2)\n",
    "            distance = distance.item() / len(tensor_list)\n",
    "            # print(distance)\n",
    "            distance_each_class_list.append(distance)\n",
    "    mean_distance_each_class = sum(distance_each_class_list) / len(distance_each_class_list)\n",
    "\n",
    "    distance_each_client_list.append(mean_distance_each_class)\n",
    "\n",
    "mean_distance_each_client = sum(distance_each_client_list) / len(distance_each_client_list)\n",
    "mean_n = sum(n_list) / len(n_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.20695072323556513"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_distance_each_client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "66.2"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5495063708378718"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(distance_each_class_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(10.9312, device='cuda:0')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.norm(tensor_list[-1] - tensor_list[-2], p=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6547251347133091"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(distance_each_client_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15, 187, 66.2)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.min(ns), np.max(ns), np.mean(ns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11528335396011004"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(distances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9624424616495768"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(distances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DomainFL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
