{"base_model": "CLIP", "dataset": "adaptiope", "subset_size": 100, "image_encoder_name": "ViT-B-32", "optimizer": "AdamW", "batch_size": 32, "learning_rate": 0.001, "global_rounds": 200, "local_epochs": 1, "warm_up": 10, "seed": 1}
{"round": 0, "acc": [[95.9, 89.28, 79.08], [95.9, 89.28, 79.08], [95.9, 89.28, 79.08]], "total_test_time": 89.39365887641907, "total_train_time": 9.66902232170105, "converge_round": 332}
