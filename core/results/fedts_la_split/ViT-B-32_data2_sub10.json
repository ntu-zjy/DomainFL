{"base_model": "CLIP", "dataset": "data2", "subset_size": 10, "image_encoder_name": "ViT-B-32", "optimizer": "AdamW", "batch_size": 128, "learning_rate": 0.001, "global_rounds": 50, "local_epochs": 1, "warm_up": 5, "seed": 1}
{"round": 0, "own_acc": [0.9707792207792207, 0.9421965317919075, 0.9969199178644764, 0.9792452830188679, 0.914, 0.8390804597701149], "other_acc": [0.8797922334899827, 0.8158347676419966, 0.8702990820254664, 0.9052604030358545, 0.7625394598386531, 0.9020828345702657], "domain_acc": 0.9600091932888991}
